urls = [
        'http://www.aboutamazon.com/our-company/',
        'http://www.intel.com/content/www/us/en/company-overview/company-overview.html']
#         'http://www.microsoft.com/en-us/about/',
#         'http://corporate.ford.com/company.html',
#         'http://www.boeing.com/company/general-info/',
#         'http://www.alliancedata.com/about-us/default.aspx',
#         'https://www.polarityte.com/about/overview/',
#         'http://www.arconic.com/what-we-do/',
#         'http://www.fico.com/en/about-us/',
#         'http://www.epizyme.com/about-us/overview-history/']

data = {}

for url in urls:
    
    html = urlopen(url)
    soup = BeautifulSoup(html, 'html.parser')
    
    # generate title
    first_title = soup.title
    title = first_title.string
    
    # create list of all instances of the word innovation, or some version of it
    innovation_instances = soup.find_all(string=re.compile("inno+"))

        
    #convert list to string and count how many times innovation is mentioned
    def listToString():  
        ii_string = " " 

        # return string   
        return (ii_string.join(innovation_instances)) 

    string = listToString()
    sub = 'inno'
    
    inno_string_count = (string.count(sub))
    
    num_words = [len(sentence.split()) for sentence in soup.find_all(string=re.compile("inno+"))]
    
    frequency = (int(inno_string_count) / num_words[0]) * 100
    
    
    data[url] = innovation_instances, title, inno_string_count, num_words[0], frequency 
    
    print(data)
    
# print(data)
    

# with open('data.txt', 'w') as outfile:
#     json.dump(data, outfile)
    